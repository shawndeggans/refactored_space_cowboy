{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf36a833-ead5-443d-9e75-1ee3f6a5a252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup - Install Libraries, Import, and Initialize\n",
    "**What this cell does:**\n",
    "\n",
    "- Installs necessary libraries\n",
    "- Imports everything we'll need for the entire notebook\n",
    "- Sets up environment variables for the Anthropic API key\n",
    "- Creates basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0a9793-2588-4d86-8ebc-adba70cf6705",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "%pip install anthropic python-dotenv pandas\n",
    "\n",
    "# Import standard libraries\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any\n",
    "import uuid\n",
    "\n",
    "# Import third-party libraries\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Anthropic client\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if api_key:\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "    print(\"Anthropic client initialized successfully\")\n",
    "else:\n",
    "    print(\"No ANTHROPIC_API_KEY found in .env file\")\n",
    "    print(\"Please create a .env file with: ANTHROPIC_API_KEY=your-key-here\")\n",
    "\n",
    "# Set display options for better DataFrame viewing\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"All imports completed\")\n",
    "print(f\"Notebook started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51d1c849-c497-4ec6-9077-c475e26164c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Initialize and Create Basic Decision Event Structure\n",
    "**What this cell does:**\n",
    "\n",
    "- Define a function to create a technical decision event\n",
    "- Include: timestamp, decision_type, title, context, rationale\n",
    "- Test by creating a sample decision about choosing DynamoDB\n",
    "- Display as a pandas DataFrame with one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bbb41ed-f19d-411c-a987-a5a5ca3a854f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_decision_event(\n",
    "    title: str,\n",
    "    decision_type: str,\n",
    "    context: str,\n",
    "    rationale: str,\n",
    "    alternatives_considered: List[str] = None,\n",
    "    tags: List[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Create a technical decision event with all necessary metadata.\"\"\"\n",
    "    return {\n",
    "        'id': f\"decision_{uuid.uuid4().hex[:8]}\",\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'event_type': 'technical_decision',\n",
    "        'decision_type': decision_type,\n",
    "        'title': title,\n",
    "        'context': context,\n",
    "        'rationale': rationale,\n",
    "        'alternatives_considered': alternatives_considered or [],\n",
    "        'tags': tags or []\n",
    "    }\n",
    "\n",
    "# Test the function with a sample decision\n",
    "sample_decision = create_decision_event(\n",
    "    title=\"Use DynamoDB for session storage\",\n",
    "    decision_type=\"database\",\n",
    "    context=\"HAS needs fast, scalable session storage for passenger flow tracking\",\n",
    "    rationale=\"DynamoDB provides millisecond latency and automatic scaling\",\n",
    "    alternatives_considered=[\"Redis\", \"RDS PostgreSQL\", \"MongoDB\"],\n",
    "    tags=[\"database\", \"aws\", \"performance\", \"scalability\"]\n",
    ")\n",
    "\n",
    "# Display as DataFrame\n",
    "df = pd.DataFrame([sample_decision])\n",
    "display(df)\n",
    "\n",
    "# Also print the raw event for inspection\n",
    "print(\"\\nRaw event structure:\")\n",
    "print(json.dumps(sample_decision, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d110abdb-11a8-4489-8b05-587bc11264f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create History Storage and Display Function\n",
    "**What this cell does:**\n",
    "\n",
    "- Initialize empty history list Y\n",
    "- Create function to add events to history\n",
    "- Create function to display history as a nice pandas DataFrame\n",
    "- Test by adding our first decision and displaying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43928fe0-fdfe-4850-b93e-9dde23f14f70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize our history (Y) - this will store all events\n",
    "Y = []\n",
    "\n",
    "def add_to_history(event: Dict[str, Any], history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Add an event to history and return the updated history.\"\"\"\n",
    "    history.append(event)\n",
    "    return history\n",
    "\n",
    "def display_history(history: List[Dict[str, Any]], last_n: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"Display history as a formatted DataFrame.\"\"\"\n",
    "    if not history:\n",
    "        print(\"History is empty\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    \n",
    "    # Select columns to display in a nice order\n",
    "    display_columns = ['timestamp', 'title', 'decision_type', 'context']\n",
    "    if 'outcome' in df.columns:\n",
    "        display_columns.append('outcome')\n",
    "    \n",
    "    # Show only last_n records if specified\n",
    "    if last_n:\n",
    "        df = df.tail(last_n)\n",
    "    \n",
    "    # Format timestamp for better readability\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%Y-%m-%d %H:%M')\n",
    "    \n",
    "    return df[display_columns]\n",
    "\n",
    "# Test by adding our sample decision to history\n",
    "Y = add_to_history(sample_decision, Y)\n",
    "\n",
    "# Display the history\n",
    "df_history = display_history(Y)\n",
    "display(df_history)\n",
    "\n",
    "print(f\"\\nTotal events in history: {len(Y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5ac939b-1194-49e1-97ad-772d2324df75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create More Decision Events\n",
    "**What this cell does:**\n",
    "\n",
    "- Create 3-4 more technical decision events\n",
    "- Mix of database choices, API designs, architecture patterns\n",
    "- Add them all to history\n",
    "- Display the growing history DataFrame to see our journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ee28b14-bf52-4509-bf67-c5c54f3fd129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create several more technical decisions to build our history\n",
    "decision_2 = create_decision_event(\n",
    "    title=\"Implement event-driven architecture for real-time updates\",\n",
    "    decision_type=\"architecture\",\n",
    "    context=\"HAS needs real-time passenger flow updates across multiple terminals\",\n",
    "    rationale=\"Event-driven pattern allows loose coupling and scalability\",\n",
    "    alternatives_considered=[\"Polling-based updates\", \"Direct database queries\", \"WebSocket connections\"],\n",
    "    tags=[\"architecture\", \"real-time\", \"scalability\", \"events\"]\n",
    ")\n",
    "\n",
    "decision_3 = create_decision_event(\n",
    "    title=\"Use GraphQL for mobile API\",\n",
    "    decision_type=\"api\",\n",
    "    context=\"Mobile app needs flexible data fetching to minimize bandwidth usage\",\n",
    "    rationale=\"GraphQL allows clients to request exactly what they need, reducing over-fetching\",\n",
    "    alternatives_considered=[\"REST API\", \"gRPC\", \"JSON-RPC\"],\n",
    "    tags=[\"api\", \"mobile\", \"performance\", \"graphql\"]\n",
    ")\n",
    "\n",
    "decision_4 = create_decision_event(\n",
    "    title=\"Choose Kubernetes for container orchestration\",\n",
    "    decision_type=\"infrastructure\",\n",
    "    context=\"Need to manage 50+ microservices across multiple environments\",\n",
    "    rationale=\"Kubernetes provides robust orchestration, auto-scaling, and self-healing\",\n",
    "    alternatives_considered=[\"Docker Swarm\", \"ECS\", \"Manual Docker deployment\"],\n",
    "    tags=[\"infrastructure\", \"containers\", \"kubernetes\", \"devops\"]\n",
    ")\n",
    "\n",
    "decision_5 = create_decision_event(\n",
    "    title=\"Use Redis for caching layer\",\n",
    "    decision_type=\"database\",\n",
    "    context=\"API response times need improvement for frequently accessed data\",\n",
    "    rationale=\"Redis provides sub-millisecond latency and built-in cache expiration\",\n",
    "    alternatives_considered=[\"Memcached\", \"DynamoDB DAX\", \"In-memory application cache\"],\n",
    "    tags=[\"database\", \"caching\", \"performance\", \"redis\"]\n",
    ")\n",
    "\n",
    "# Add all decisions to history\n",
    "for decision in [decision_2, decision_3, decision_4, decision_5]:\n",
    "    Y = add_to_history(decision, Y)\n",
    "\n",
    "# Display the complete history\n",
    "df_history = display_history(Y)\n",
    "display(df_history)\n",
    "\n",
    "print(f\"\\nTotal events in history: {len(Y)}\")\n",
    "print(f\"Decision types: {df_history['decision_type'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5435729-130c-400b-9339-d10071bb8110",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Query History Function - Find Related Decisions\n",
    "**What this cell does:**\n",
    "\n",
    "- Create function to search history for related decisions\n",
    "- Input: keywords or topic (e.g., \"database\", \"API\")\n",
    "- Output: filtered DataFrame of relevant past decisions\n",
    "- Test with \"database\" to find all DB-related decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d1f66d7-5f2e-4828-ac29-ddca947e2637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def query_history(history: List[Dict[str, Any]], search_term: str) -> pd.DataFrame:\n",
    "    \"\"\"Search history for decisions related to a search term.\"\"\"\n",
    "    search_term_lower = search_term.lower()\n",
    "    related_events = []\n",
    "    \n",
    "    for event in history:\n",
    "        # Search in multiple fields\n",
    "        searchable_text = ' '.join([\n",
    "            event.get('title', ''),\n",
    "            event.get('context', ''),\n",
    "            event.get('rationale', ''),\n",
    "            event.get('decision_type', ''),\n",
    "            ' '.join(event.get('tags', [])),\n",
    "            ' '.join(event.get('alternatives_considered', []))\n",
    "        ]).lower()\n",
    "        \n",
    "        if search_term_lower in searchable_text:\n",
    "            related_events.append(event)\n",
    "    \n",
    "    if not related_events:\n",
    "        print(f\"No decisions found related to '{search_term}'\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return display_history(related_events)\n",
    "\n",
    "# Test with different search terms\n",
    "print(\"=== Searching for 'database' related decisions ===\")\n",
    "db_decisions = query_history(Y, \"database\")\n",
    "display(db_decisions)\n",
    "\n",
    "print(\"\\n=== Searching for 'performance' related decisions ===\")\n",
    "perf_decisions = query_history(Y, \"performance\")\n",
    "display(perf_decisions)\n",
    "\n",
    "print(\"\\n=== Searching for 'API' related decisions ===\")\n",
    "api_decisions = query_history(Y, \"api\")\n",
    "display(api_decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d25e28d2-2597-4be1-9044-226b72bc303a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Simple Pattern Detection Function\n",
    "**What this cell does:**\n",
    "\n",
    "- Create function to identify decision patterns without LLM\n",
    "- Example: count decisions by type, identify frequent topics\n",
    "- Return summary statistics as DataFrame\n",
    "- Shows what we have before adding intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c4cd26b-8f06-408f-a472-940a9130ef0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_patterns(history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Analyze patterns in decision history without LLM.\"\"\"\n",
    "    if not history:\n",
    "        return {\"error\": \"No history to analyze\"}\n",
    "    \n",
    "    # Count decisions by type\n",
    "    type_counts = {}\n",
    "    for event in history:\n",
    "        decision_type = event.get('decision_type', 'unknown')\n",
    "        type_counts[decision_type] = type_counts.get(decision_type, 0) + 1\n",
    "    \n",
    "    # Count all tags\n",
    "    tag_counts = {}\n",
    "    for event in history:\n",
    "        for tag in event.get('tags', []):\n",
    "            tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "    \n",
    "    # Find most considered alternatives\n",
    "    alternative_counts = {}\n",
    "    for event in history:\n",
    "        for alt in event.get('alternatives_considered', []):\n",
    "            alternative_counts[alt] = alternative_counts.get(alt, 0) + 1\n",
    "    \n",
    "    # Time-based analysis\n",
    "    df_temp = pd.DataFrame(history)\n",
    "    df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])\n",
    "    df_temp['hour'] = df_temp['timestamp'].dt.hour\n",
    "    df_temp['day_of_week'] = df_temp['timestamp'].dt.day_name()\n",
    "    \n",
    "    return {\n",
    "        'decision_types': type_counts,\n",
    "        'top_tags': dict(sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:5]),\n",
    "        'alternatives_considered': dict(sorted(alternative_counts.items(), key=lambda x: x[1], reverse=True)[:5]),\n",
    "        'total_decisions': len(history),\n",
    "        'decisions_by_hour': df_temp['hour'].value_counts().to_dict(),\n",
    "        'decisions_by_day': df_temp['day_of_week'].value_counts().to_dict()\n",
    "    }\n",
    "\n",
    "# Analyze current patterns\n",
    "patterns = analyze_patterns(Y)\n",
    "\n",
    "# Display results in a nice format\n",
    "print(\"=== Decision Pattern Analysis ===\\n\")\n",
    "print(\"Decision Types:\")\n",
    "display(pd.DataFrame(list(patterns['decision_types'].items()), columns=['Type', 'Count']))\n",
    "\n",
    "print(\"\\nTop Tags:\")\n",
    "display(pd.DataFrame(list(patterns['top_tags'].items()), columns=['Tag', 'Count']))\n",
    "\n",
    "print(\"\\nMost Considered Alternatives:\")\n",
    "display(pd.DataFrame(list(patterns['alternatives_considered'].items()), columns=['Alternative', 'Times Considered']))\n",
    "\n",
    "print(f\"\\nTotal Decisions: {patterns['total_decisions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1454e573-409f-4e24-8162-a914fddaeca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Add Consequence Events - Track Decision Outcomes\n",
    "**What this cell does:**\n",
    "\n",
    "- Create new event type for consequences/outcomes of decisions\n",
    "- Link consequences back to original decisions via decision_id\n",
    "- Add several consequences to our existing decisions\n",
    "- Display enhanced history showing decisions with their outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "931e4563-3c45-40ad-967b-2cb1354c4246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_consequence_event(\n",
    "    original_decision_id: str,\n",
    "    outcome: str,\n",
    "    impact: str,\n",
    "    lessons_learned: str,\n",
    "    tags: List[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Create a consequence event linked to an original decision.\"\"\"\n",
    "    return {\n",
    "        'id': f\"consequence_{uuid.uuid4().hex[:8]}\",\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'event_type': 'decision_consequence',\n",
    "        'original_decision_id': original_decision_id,\n",
    "        'outcome': outcome,\n",
    "        'impact': impact,\n",
    "        'lessons_learned': lessons_learned,\n",
    "        'tags': tags or []\n",
    "    }\n",
    "\n",
    "# Create consequences for our existing decisions\n",
    "consequence_1 = create_consequence_event(\n",
    "    original_decision_id=Y[0]['id'],  # DynamoDB decision\n",
    "    outcome=\"DynamoDB costs exceeded budget by 40%\",\n",
    "    impact=\"Had to implement aggressive TTL policies and optimize read/write capacity\",\n",
    "    lessons_learned=\"Always model costs with realistic traffic projections\",\n",
    "    tags=[\"cost-overrun\", \"database\", \"aws\"]\n",
    ")\n",
    "\n",
    "consequence_2 = create_consequence_event(\n",
    "    original_decision_id=Y[1]['id'],  # Event-driven architecture\n",
    "    outcome=\"Event processing achieved sub-100ms latency\",\n",
    "    impact=\"Successfully handled 10x traffic spike during holiday travel\",\n",
    "    lessons_learned=\"Event-driven architecture provides excellent scalability\",\n",
    "    tags=[\"success\", \"performance\", \"architecture\"]\n",
    ")\n",
    "\n",
    "consequence_3 = create_consequence_event(\n",
    "    original_decision_id=Y[2]['id'],  # GraphQL API\n",
    "    outcome=\"Mobile app data usage reduced by 60%\",\n",
    "    impact=\"Improved user experience and reduced AWS data transfer costs\",\n",
    "    lessons_learned=\"GraphQL complexity worth it for mobile optimization\",\n",
    "    tags=[\"success\", \"mobile\", \"cost-savings\"]\n",
    ")\n",
    "\n",
    "consequence_4 = create_consequence_event(\n",
    "    original_decision_id=Y[3]['id'],  # Kubernetes\n",
    "    outcome=\"Kubernetes cluster management required dedicated DevOps hire\",\n",
    "    impact=\"Increased operational costs but improved deployment reliability\",\n",
    "    lessons_learned=\"Consider managed services (EKS) vs self-managed for small teams\",\n",
    "    tags=[\"operational-cost\", \"team-growth\", \"infrastructure\"]\n",
    ")\n",
    "\n",
    "# Add all consequences to history\n",
    "for consequence in [consequence_1, consequence_2, consequence_3, consequence_4]:\n",
    "    Y = add_to_history(consequence, Y)\n",
    "\n",
    "# Create an enhanced display function that shows relationships\n",
    "def display_decisions_with_consequences(history: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Display decisions along with their consequences.\"\"\"\n",
    "    # Separate decisions and consequences\n",
    "    decisions = [e for e in history if e.get('event_type') == 'technical_decision']\n",
    "    consequences = [e for e in history if e.get('event_type') == 'decision_consequence']\n",
    "    \n",
    "    # Create a map of consequences by decision_id\n",
    "    consequences_map = {}\n",
    "    for c in consequences:\n",
    "        decision_id = c.get('original_decision_id')\n",
    "        if decision_id not in consequences_map:\n",
    "            consequences_map[decision_id] = []\n",
    "        consequences_map[decision_id].append(c)\n",
    "    \n",
    "    # Display each decision with its consequences\n",
    "    for decision in decisions:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"DECISION: {decision['title']}\")\n",
    "        print(f\"Type: {decision['decision_type']} | Date: {decision['timestamp'][:10]}\")\n",
    "        print(f\"Context: {decision['context']}\")\n",
    "        \n",
    "        # Check if there are consequences\n",
    "        decision_consequences = consequences_map.get(decision['id'], [])\n",
    "        if decision_consequences:\n",
    "            print(f\"\\nCONSEQUENCES ({len(decision_consequences)}):\")\n",
    "            for i, cons in enumerate(decision_consequences, 1):\n",
    "                print(f\"  {i}. Outcome: {cons['outcome']}\")\n",
    "                print(f\"     Impact: {cons['impact']}\")\n",
    "                print(f\"     Lesson: {cons['lessons_learned']}\")\n",
    "\n",
    "# Display the enhanced view\n",
    "display_decisions_with_consequences(Y)\n",
    "\n",
    "# Also show summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY STATISTICS:\")\n",
    "print(f\"Total Events: {len(Y)}\")\n",
    "print(f\"Decisions: {len([e for e in Y if e.get('event_type') == 'technical_decision'])}\")\n",
    "print(f\"Consequences: {len([e for e in Y if e.get('event_type') == 'decision_consequence'])}\")\n",
    "\n",
    "# Show recent history in DataFrame format\n",
    "print(\"\\nRecent History (last 5 events):\")\n",
    "df_recent = display_history(Y, last_n=5)\n",
    "display(df_recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77809780-abfc-4f7f-b211-0fb6f4da3edd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Create Context Builder for LLM\n",
    "**What this cell does:**\n",
    "\n",
    "- Function to build relevant context from history for a new decision\n",
    "- Input: new decision topic\n",
    "- Output: formatted string of relevant past decisions and outcomes\n",
    "- Test with a new decision topic like \"caching strategy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36e369ad-a392-47c5-84b7-b72df10028c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_context_for_decision(topic: str, history: List[Dict[str, Any]], max_items: int = 5) -> str:\n",
    "    \"\"\"Build relevant context from history for a new decision topic.\"\"\"\n",
    "    # Search for related decisions and consequences\n",
    "    related_items = []\n",
    "    topic_lower = topic.lower()\n",
    "    \n",
    "    for event in history:\n",
    "        # Create searchable text from the event\n",
    "        searchable_text = ' '.join([\n",
    "            event.get('title', ''),\n",
    "            event.get('context', ''),\n",
    "            event.get('rationale', ''),\n",
    "            event.get('outcome', ''),\n",
    "            event.get('impact', ''),\n",
    "            event.get('lessons_learned', ''),\n",
    "            ' '.join(event.get('tags', [])),\n",
    "            ' '.join(event.get('alternatives_considered', []))\n",
    "        ]).lower()\n",
    "        \n",
    "        if topic_lower in searchable_text or any(word in searchable_text for word in topic_lower.split()):\n",
    "            related_items.append(event)\n",
    "    \n",
    "    # Sort by relevance (simple: number of topic words found)\n",
    "    def relevance_score(event):\n",
    "        searchable = ' '.join(str(v) for v in event.values()).lower()\n",
    "        return sum(1 for word in topic_lower.split() if word in searchable)\n",
    "    \n",
    "    related_items.sort(key=relevance_score, reverse=True)\n",
    "    related_items = related_items[:max_items]\n",
    "    \n",
    "    # Build context string\n",
    "    context_parts = [f\"Context for decision about: {topic}\\n\"]\n",
    "    context_parts.append(f\"Found {len(related_items)} related items from history:\\n\")\n",
    "    \n",
    "    for i, item in enumerate(related_items, 1):\n",
    "        context_parts.append(f\"\\n{i}. {item.get('event_type', 'unknown').replace('_', ' ').title()}\")\n",
    "        \n",
    "        if item.get('event_type') == 'technical_decision':\n",
    "            context_parts.append(f\"   Title: {item['title']}\")\n",
    "            context_parts.append(f\"   Context: {item['context']}\")\n",
    "            context_parts.append(f\"   Rationale: {item['rationale']}\")\n",
    "            context_parts.append(f\"   Alternatives: {', '.join(item.get('alternatives_considered', []))}\")\n",
    "        \n",
    "        elif item.get('event_type') == 'decision_consequence':\n",
    "            context_parts.append(f\"   Outcome: {item['outcome']}\")\n",
    "            context_parts.append(f\"   Impact: {item['impact']}\")\n",
    "            context_parts.append(f\"   Lesson: {item['lessons_learned']}\")\n",
    "        \n",
    "        context_parts.append(f\"   Tags: {', '.join(item.get('tags', []))}\")\n",
    "    \n",
    "    return '\\n'.join(context_parts)\n",
    "\n",
    "# Test with different decision topics\n",
    "print(\"=== Context for 'caching strategy' decision ===\")\n",
    "caching_context = build_context_for_decision(\"caching strategy\", Y)\n",
    "print(caching_context)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"=== Context for 'cost optimization' decision ===\")\n",
    "cost_context = build_context_for_decision(\"cost optimization\", Y)\n",
    "print(cost_context)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"=== Context for 'monitoring infrastructure' decision ===\")\n",
    "monitoring_context = build_context_for_decision(\"monitoring infrastructure\", Y)\n",
    "print(monitoring_context)\n",
    "\n",
    "# Also create a function to get context as structured data\n",
    "def get_structured_context(topic: str, history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Get context as structured data for programmatic use.\"\"\"\n",
    "    related_decisions = []\n",
    "    related_consequences = []\n",
    "    \n",
    "    topic_lower = topic.lower()\n",
    "    \n",
    "    for event in history:\n",
    "        searchable = ' '.join(str(v) for v in event.values()).lower()\n",
    "        if topic_lower in searchable or any(word in searchable for word in topic_lower.split()):\n",
    "            if event.get('event_type') == 'technical_decision':\n",
    "                related_decisions.append(event)\n",
    "            elif event.get('event_type') == 'decision_consequence':\n",
    "                related_consequences.append(event)\n",
    "    \n",
    "    return {\n",
    "        'topic': topic,\n",
    "        'related_decisions': related_decisions[:3],\n",
    "        'related_consequences': related_consequences[:3],\n",
    "        'total_related': len(related_decisions) + len(related_consequences)\n",
    "    }\n",
    "\n",
    "# Test structured context\n",
    "struct_context = get_structured_context(\"database\", Y)\n",
    "print(f\"\\nStructured context for 'database':\")\n",
    "print(f\"- Related decisions: {len(struct_context['related_decisions'])}\")\n",
    "print(f\"- Related consequences: {len(struct_context['related_consequences'])}\")\n",
    "print(f\"- Total related items: {struct_context['total_related']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77ba07a0-849f-4420-86b6-152f32b3464a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### LLM Integration - Analyze Decision Consistency\n",
    "**What this cell does:**\n",
    "\n",
    "- Create function that uses LLM to check if new decision aligns with past decisions\n",
    "- Input: new decision + relevant history context\n",
    "- Output: analysis of consistency, potential conflicts\n",
    "- Display as formatted markdown or DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d15fae49-b75e-47ad-b925-a4fb493cf64c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analyze_decision_consistency(new_decision: Dict[str, Any], history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Use LLM to analyze if a new decision aligns with past decisions.\"\"\"\n",
    "    # Build context from history\n",
    "    decision_topic = f\"{new_decision['decision_type']} {new_decision['title']}\"\n",
    "    historical_context = build_context_for_decision(decision_topic, history, max_items=10)\n",
    "    \n",
    "    # Create prompt for LLM\n",
    "    prompt = f\"\"\"Analyze the consistency of this new technical decision with our past decisions and their outcomes.\n",
    "\n",
    "NEW DECISION:\n",
    "Title: {new_decision['title']}\n",
    "Type: {new_decision['decision_type']}\n",
    "Context: {new_decision['context']}\n",
    "Rationale: {new_decision['rationale']}\n",
    "Alternatives Considered: {', '.join(new_decision.get('alternatives_considered', []))}\n",
    "\n",
    "HISTORICAL CONTEXT:\n",
    "{historical_context}\n",
    "\n",
    "Please analyze:\n",
    "1. CONSISTENCY: Does this decision align with our past decisions and learned lessons?\n",
    "2. CONFLICTS: Are there any contradictions with previous choices or their outcomes?\n",
    "3. PATTERNS: What patterns from our history support or challenge this decision?\n",
    "4. RISKS: Based on past consequences, what risks should we consider?\n",
    "5. RECOMMENDATIONS: Specific suggestions based on our history\n",
    "\n",
    "Format your response as JSON with these exact keys: consistency_score (0-100), conflicts, supporting_patterns, risks, recommendations.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",\n",
    "            max_tokens=1000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response_text = response.content[0].text\n",
    "        \n",
    "        # Try to extract JSON from response\n",
    "        import re\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            analysis = json.loads(json_match.group())\n",
    "        else:\n",
    "            # Fallback if JSON parsing fails\n",
    "            analysis = {\n",
    "                \"consistency_score\": 0,\n",
    "                \"analysis_text\": response_text,\n",
    "                \"error\": \"Could not parse structured response\"\n",
    "            }\n",
    "            \n",
    "        return {\n",
    "            \"new_decision\": new_decision['title'],\n",
    "            \"analysis\": analysis,\n",
    "            \"historical_items_reviewed\": len([e for e in history if decision_topic.lower() in str(e).lower()])\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"new_decision\": new_decision['title'],\n",
    "            \"error\": str(e),\n",
    "            \"analysis\": None\n",
    "        }\n",
    "\n",
    "# Test with a new decision that should align well\n",
    "aligned_decision = create_decision_event(\n",
    "    title=\"Implement distributed caching with Redis Cluster\",\n",
    "    decision_type=\"infrastructure\",\n",
    "    context=\"Need to scale caching solution across multiple availability zones\",\n",
    "    rationale=\"Redis Cluster provides horizontal scaling and high availability\",\n",
    "    alternatives_considered=[\"Hazelcast\", \"Apache Ignite\", \"ElastiCache\"],\n",
    "    tags=[\"caching\", \"redis\", \"scalability\", \"infrastructure\"]\n",
    ")\n",
    "\n",
    "print(\"=== Testing Aligned Decision ===\")\n",
    "consistency_analysis = analyze_decision_consistency(aligned_decision, Y)\n",
    "\n",
    "if consistency_analysis.get('analysis'):\n",
    "    print(f\"\\nDecision: {consistency_analysis['new_decision']}\")\n",
    "    print(f\"Historical items reviewed: {consistency_analysis['historical_items_reviewed']}\")\n",
    "    \n",
    "    analysis = consistency_analysis['analysis']\n",
    "    if 'consistency_score' in analysis:\n",
    "        print(f\"\\nConsistency Score: {analysis.get('consistency_score', 'N/A')}/100\")\n",
    "        print(f\"\\nConflicts: {analysis.get('conflicts', 'None identified')}\")\n",
    "        print(f\"\\nSupporting Patterns: {analysis.get('supporting_patterns', 'None identified')}\")\n",
    "        print(f\"\\nRisks: {analysis.get('risks', 'None identified')}\")\n",
    "        print(f\"\\nRecommendations: {analysis.get('recommendations', 'None provided')}\")\n",
    "    else:\n",
    "        print(\"\\nAnalysis Text:\")\n",
    "        print(analysis.get('analysis_text', 'No analysis available'))\n",
    "else:\n",
    "    print(f\"Error: {consistency_analysis.get('error')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test with a potentially conflicting decision\n",
    "conflicting_decision = create_decision_event(\n",
    "    title=\"Replace all caching with direct database queries\",\n",
    "    decision_type=\"architecture\",\n",
    "    context=\"Simplify architecture by removing caching layer\",\n",
    "    rationale=\"Reduce complexity and avoid cache invalidation issues\",\n",
    "    alternatives_considered=[\"Keep Redis\", \"Use CDN only\", \"In-memory caching\"],\n",
    "    tags=[\"architecture\", \"simplification\", \"database\"]\n",
    ")\n",
    "\n",
    "print(\"=== Testing Potentially Conflicting Decision ===\")\n",
    "conflict_analysis = analyze_decision_consistency(conflicting_decision, Y)\n",
    "\n",
    "if conflict_analysis.get('analysis'):\n",
    "    print(f\"\\nDecision: {conflict_analysis['new_decision']}\")\n",
    "    print(f\"Historical items reviewed: {conflict_analysis['historical_items_reviewed']}\")\n",
    "    \n",
    "    analysis = conflict_analysis['analysis']\n",
    "    if 'consistency_score' in analysis:\n",
    "        print(f\"\\nConsistency Score: {analysis.get('consistency_score', 'N/A')}/100\")\n",
    "        print(f\"\\nConflicts: {analysis.get('conflicts', 'None identified')}\")\n",
    "        print(f\"\\nSupporting Patterns: {analysis.get('supporting_patterns', 'None identified')}\")\n",
    "        print(f\"\\nRisks: {analysis.get('risks', 'None identified')}\")\n",
    "        print(f\"\\nRecommendations: {analysis.get('recommendations', 'None provided')}\")\n",
    "    else:\n",
    "        print(\"\\nAnalysis Text:\")\n",
    "        print(analysis.get('analysis_text', 'No analysis available'))\n",
    "else:\n",
    "    print(f\"Error: {conflict_analysis.get('error')}\")\n",
    "\n",
    "# Create a summary DataFrame of analyses\n",
    "analyses_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Decision': 'Distributed Redis Caching',\n",
    "        'Type': 'infrastructure',\n",
    "        'Consistency': consistency_analysis.get('analysis', {}).get('consistency_score', 'N/A')\n",
    "    },\n",
    "    {\n",
    "        'Decision': 'Remove Caching Layer',\n",
    "        'Type': 'architecture', \n",
    "        'Consistency': conflict_analysis.get('analysis', {}).get('consistency_score', 'N/A')\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n=== Analysis Summary ===\")\n",
    "display(analyses_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3581ed6-8fe1-45bc-a622-47d815b4f9d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### LLM Pattern Recognition\n",
    "**What this cell does:**\n",
    "\n",
    "- Function for LLM to identify patterns across all decisions\n",
    "- What types of decisions lead to what outcomes?\n",
    "- What decisions tend to cluster together?\n",
    "- Display insights as structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b235a1ae-7f3c-44a3-bec4-76f3fb148406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def recognize_decision_patterns(history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Use LLM to identify patterns across all technical decisions.\"\"\"\n",
    "    # Prepare history summary for analysis\n",
    "    decisions = [e for e in history if e.get('event_type') == 'technical_decision']\n",
    "    consequences = [e for e in history if e.get('event_type') == 'decision_consequence']\n",
    "    \n",
    "    # Create decision-consequence pairs\n",
    "    consequence_map = {}\n",
    "    for cons in consequences:\n",
    "        consequence_map[cons.get('original_decision_id')] = cons\n",
    "    \n",
    "    history_summary = []\n",
    "    for dec in decisions:\n",
    "        summary_item = {\n",
    "            'decision': dec['title'],\n",
    "            'type': dec['decision_type'],\n",
    "            'tags': dec.get('tags', []),\n",
    "            'alternatives': dec.get('alternatives_considered', [])\n",
    "        }\n",
    "        if dec['id'] in consequence_map:\n",
    "            cons = consequence_map[dec['id']]\n",
    "            summary_item['outcome'] = cons['outcome']\n",
    "            summary_item['lesson'] = cons['lessons_learned']\n",
    "        history_summary.append(summary_item)\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this technical decision history to identify patterns, trends, and insights.\n",
    "\n",
    "DECISION HISTORY:\n",
    "{json.dumps(history_summary, indent=2)}\n",
    "\n",
    "Please identify:\n",
    "1. DECISION PATTERNS: What types of decisions tend to lead to what types of outcomes?\n",
    "2. CLUSTERING: Which decisions tend to be made together or in sequence?\n",
    "3. SUCCESS FACTORS: What characteristics are common in successful decisions?\n",
    "4. FAILURE PATTERNS: What warning signs appear in decisions that led to problems?\n",
    "5. TECHNOLOGY PREFERENCES: What consistent technology choices emerge?\n",
    "6. LEARNING CURVE: How have decision-making patterns evolved over time?\n",
    "\n",
    "Format your response as JSON with these keys: decision_patterns, decision_clusters, success_factors, failure_patterns, technology_preferences, evolution_insights.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",\n",
    "            max_tokens=1500,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        response_text = response.content[0].text\n",
    "        \n",
    "        # Extract JSON\n",
    "        import re\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            patterns = json.loads(json_match.group())\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"patterns\": patterns,\n",
    "                \"decisions_analyzed\": len(decisions),\n",
    "                \"consequences_analyzed\": len(consequences)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"raw_response\": response_text,\n",
    "                \"decisions_analyzed\": len(decisions),\n",
    "                \"consequences_analyzed\": len(consequences)\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e),\n",
    "            \"decisions_analyzed\": len(decisions),\n",
    "            \"consequences_analyzed\": len(consequences)\n",
    "        }\n",
    "\n",
    "# Run pattern recognition\n",
    "print(\"=== Analyzing Decision Patterns Across History ===\\n\")\n",
    "pattern_analysis = recognize_decision_patterns(Y)\n",
    "\n",
    "if pattern_analysis['status'] == 'success':\n",
    "    print(f\"Analyzed {pattern_analysis['decisions_analyzed']} decisions and {pattern_analysis['consequences_analyzed']} consequences\\n\")\n",
    "    \n",
    "    patterns = pattern_analysis['patterns']\n",
    "    \n",
    "    # Display each pattern category\n",
    "    for key, value in patterns.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{key.replace('_', ' ').upper()}:\")\n",
    "        print('='*60)\n",
    "        \n",
    "        if isinstance(value, list):\n",
    "            for i, item in enumerate(value, 1):\n",
    "                print(f\"{i}. {item}\")\n",
    "        elif isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                print(f\"- {k}: {v}\")\n",
    "        else:\n",
    "            print(value)\n",
    "else:\n",
    "    print(f\"Error analyzing patterns: {pattern_analysis.get('error', 'Unknown error')}\")\n",
    "    if 'raw_response' in pattern_analysis:\n",
    "        print(\"\\nRaw response:\")\n",
    "        print(pattern_analysis['raw_response'])\n",
    "\n",
    "# Create a visual summary of key insights\n",
    "def create_pattern_summary(patterns: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Create a summary DataFrame of key pattern insights.\"\"\"\n",
    "    if not patterns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    # Extract key metrics if available\n",
    "    if 'success_factors' in patterns:\n",
    "        summary_data.append({\n",
    "            'Category': 'Success Factors',\n",
    "            'Count': len(patterns['success_factors']) if isinstance(patterns['success_factors'], list) else 1,\n",
    "            'Key Insight': patterns['success_factors'][0] if isinstance(patterns['success_factors'], list) else str(patterns['success_factors'])[:100]\n",
    "        })\n",
    "    \n",
    "    if 'failure_patterns' in patterns:\n",
    "        summary_data.append({\n",
    "            'Category': 'Failure Patterns',\n",
    "            'Count': len(patterns['failure_patterns']) if isinstance(patterns['failure_patterns'], list) else 1,\n",
    "            'Key Insight': patterns['failure_patterns'][0] if isinstance(patterns['failure_patterns'], list) else str(patterns['failure_patterns'])[:100]\n",
    "        })\n",
    "    \n",
    "    if 'technology_preferences' in patterns:\n",
    "        tech_prefs = patterns['technology_preferences']\n",
    "        if isinstance(tech_prefs, dict):\n",
    "            summary_data.append({\n",
    "                'Category': 'Technology Preferences',\n",
    "                'Count': len(tech_prefs),\n",
    "                'Key Insight': f\"Preferred: {', '.join(list(tech_prefs.keys())[:3])}\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(summary_data)\n",
    "\n",
    "if pattern_analysis['status'] == 'success' and 'patterns' in pattern_analysis:\n",
    "    print(\"\\n\\n=== Pattern Summary ===\")\n",
    "    summary_df = create_pattern_summary(pattern_analysis['patterns'])\n",
    "    if not summary_df.empty:\n",
    "        display(summary_df)\n",
    "\n",
    "# Also analyze decision frequency over time\n",
    "print(\"\\n=== Decision Frequency Analysis ===\")\n",
    "df_decisions = pd.DataFrame([e for e in Y if e.get('event_type') == 'technical_decision'])\n",
    "df_decisions['timestamp'] = pd.to_datetime(df_decisions['timestamp'])\n",
    "df_decisions['date'] = df_decisions['timestamp'].dt.date\n",
    "\n",
    "decision_freq = df_decisions.groupby('decision_type').size().reset_index(name='count')\n",
    "print(\"\\nDecisions by Type:\")\n",
    "display(decision_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8020c74-705b-4b2c-93cd-cc75bc9acb49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Decision Impact Prediction\n",
    "**What this cell does:**\n",
    "\n",
    "- Function where LLM predicts potential consequences of a new decision\n",
    "- Based on patterns from past decisions and their outcomes\n",
    "- Input: proposed decision\n",
    "- Output: predicted impacts, similar past situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37230423-5868-44dd-b0e9-d1112d2bfa4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_decision_impact(proposed_decision: Dict[str, Any], history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Use LLM to predict potential consequences of a proposed decision.\"\"\"\n",
    "    # Get structured context\n",
    "    struct_context = get_structured_context(\n",
    "        f\"{proposed_decision['decision_type']} {proposed_decision['title']}\", \n",
    "        history\n",
    "    )\n",
    "    \n",
    "    # Prepare decision-outcome pairs for analysis\n",
    "    decisions_with_outcomes = []\n",
    "    consequences_by_id = {c['original_decision_id']: c for c in history if c.get('event_type') == 'decision_consequence'}\n",
    "    \n",
    "    for decision in struct_context['related_decisions']:\n",
    "        item = {\n",
    "            'decision': decision['title'],\n",
    "            'type': decision['decision_type'],\n",
    "            'context': decision['context'],\n",
    "            'rationale': decision['rationale']\n",
    "        }\n",
    "        if decision['id'] in consequences_by_id:\n",
    "            consequence = consequences_by_id[decision['id']]\n",
    "            item['actual_outcome'] = consequence['outcome']\n",
    "            item['actual_impact'] = consequence['impact']\n",
    "            item['lessons'] = consequence['lessons_learned']\n",
    "        decisions_with_outcomes.append(item)\n",
    "    \n",
    "    prompt = f\"\"\"Based on our historical decisions and their outcomes, predict the potential consequences of this proposed decision.\n",
    "\n",
    "PROPOSED DECISION:\n",
    "Title: {proposed_decision['title']}\n",
    "Type: {proposed_decision['decision_type']}\n",
    "Context: {proposed_decision['context']}\n",
    "Rationale: {proposed_decision['rationale']}\n",
    "Alternatives: {', '.join(proposed_decision.get('alternatives_considered', []))}\n",
    "\n",
    "SIMILAR PAST DECISIONS AND OUTCOMES:\n",
    "{json.dumps(decisions_with_outcomes, indent=2)}\n",
    "\n",
    "Please predict:\n",
    "1. LIKELY_OUTCOMES: Most probable consequences (both positive and negative)\n",
    "2. IMPACT_TIMELINE: When these impacts will likely manifest\n",
    "3. RISK_FACTORS: Specific risks based on similar past decisions\n",
    "4. SUCCESS_CONDITIONS: What needs to be true for this decision to succeed\n",
    "5. SIMILAR_SITUATIONS: Past decisions most relevant to this one\n",
    "6. CONFIDENCE_LEVEL: How confident are you in these predictions (0-100)\n",
    "\n",
    "Format as JSON with these exact keys: likely_outcomes, impact_timeline, risk_factors, success_conditions, similar_situations, confidence_level.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",\n",
    "            max_tokens=1500,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        response_text = response.content[0].text\n",
    "        \n",
    "        # Extract JSON\n",
    "        import re\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            predictions = json.loads(json_match.group())\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"decision\": proposed_decision['title'],\n",
    "                \"predictions\": predictions,\n",
    "                \"historical_context_size\": len(decisions_with_outcomes)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"decision\": proposed_decision['title'],\n",
    "                \"raw_response\": response_text\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"decision\": proposed_decision['title'],\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Test with a new monitoring decision\n",
    "monitoring_decision = create_decision_event(\n",
    "    title=\"Implement DataDog for comprehensive monitoring\",\n",
    "    decision_type=\"infrastructure\",\n",
    "    context=\"Need unified monitoring across all services and infrastructure\",\n",
    "    rationale=\"DataDog provides integrated APM, logs, and infrastructure monitoring\",\n",
    "    alternatives_considered=[\"Prometheus + Grafana\", \"AWS CloudWatch\", \"New Relic\"],\n",
    "    tags=[\"monitoring\", \"observability\", \"infrastructure\"]\n",
    ")\n",
    "\n",
    "print(\"=== Predicting Impact of Monitoring Decision ===\\n\")\n",
    "impact_prediction = predict_decision_impact(monitoring_decision, Y)\n",
    "\n",
    "if impact_prediction['status'] == 'success':\n",
    "    print(f\"Decision: {impact_prediction['decision']}\")\n",
    "    print(f\"Historical context: {impact_prediction['historical_context_size']} similar decisions analyzed\\n\")\n",
    "    \n",
    "    predictions = impact_prediction['predictions']\n",
    "    \n",
    "    print(f\"Confidence Level: {predictions.get('confidence_level', 'N/A')}%\\n\")\n",
    "    \n",
    "    print(\"LIKELY OUTCOMES:\")\n",
    "    for outcome in predictions.get('likely_outcomes', []):\n",
    "        print(f\"- {outcome}\")\n",
    "    \n",
    "    print(\"\\nIMPACT TIMELINE:\")\n",
    "    timeline = predictions.get('impact_timeline', {})\n",
    "    if isinstance(timeline, dict):\n",
    "        for period, impact in timeline.items():\n",
    "            print(f\"- {period}: {impact}\")\n",
    "    else:\n",
    "        print(f\"- {timeline}\")\n",
    "    \n",
    "    print(\"\\nRISK FACTORS:\")\n",
    "    for risk in predictions.get('risk_factors', []):\n",
    "        print(f\"- {risk}\")\n",
    "    \n",
    "    print(\"\\nSUCCESS CONDITIONS:\")\n",
    "    for condition in predictions.get('success_conditions', []):\n",
    "        print(f\"- {condition}\")\n",
    "    \n",
    "    print(\"\\nSIMILAR SITUATIONS:\")\n",
    "    for situation in predictions.get('similar_situations', []):\n",
    "        print(f\"- {situation}\")\n",
    "else:\n",
    "    print(f\"Error: {impact_prediction.get('error', 'Unknown error')}\")\n",
    "\n",
    "# Test with another decision - microservices migration\n",
    "microservices_decision = create_decision_event(\n",
    "    title=\"Migrate monolithic application to microservices\",\n",
    "    decision_type=\"architecture\",\n",
    "    context=\"Current monolith becoming difficult to scale and deploy\",\n",
    "    rationale=\"Microservices will enable independent scaling and deployment\",\n",
    "    alternatives_considered=[\"Modular monolith\", \"Serverless functions\", \"Keep monolith but optimize\"],\n",
    "    tags=[\"architecture\", \"microservices\", \"scalability\"]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"=== Predicting Impact of Microservices Migration ===\\n\")\n",
    "micro_prediction = predict_decision_impact(microservices_decision, Y)\n",
    "\n",
    "if micro_prediction['status'] == 'success':\n",
    "    print(f\"Decision: {micro_prediction['decision']}\")\n",
    "    print(f\"Confidence Level: {micro_prediction['predictions'].get('confidence_level', 'N/A')}%\\n\")\n",
    "    \n",
    "    # Create a comparison DataFrame\n",
    "    comparison_data = []\n",
    "    \n",
    "    for decision_name, prediction in [(\"DataDog Monitoring\", impact_prediction), (\"Microservices Migration\", micro_prediction)]:\n",
    "        if prediction['status'] == 'success':\n",
    "            pred = prediction['predictions']\n",
    "            comparison_data.append({\n",
    "                'Decision': decision_name,\n",
    "                'Confidence': f\"{pred.get('confidence_level', 0)}%\",\n",
    "                'Risk Count': len(pred.get('risk_factors', [])),\n",
    "                'Success Conditions': len(pred.get('success_conditions', [])),\n",
    "                'Timeline': 'Short-term' if 'immediate' in str(pred.get('impact_timeline', '')).lower() else 'Long-term'\n",
    "            })\n",
    "    \n",
    "    if comparison_data:\n",
    "        print(\"\\n=== Decision Impact Comparison ===\")\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        display(comparison_df)\n",
    "\n",
    "# Add a helper function to summarize predictions\n",
    "def summarize_prediction(prediction_result: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create a concise summary of impact predictions.\"\"\"\n",
    "    if prediction_result['status'] != 'success':\n",
    "        return \"Prediction failed\"\n",
    "    \n",
    "    pred = prediction_result['predictions']\n",
    "    confidence = pred.get('confidence_level', 0)\n",
    "    risks = len(pred.get('risk_factors', []))\n",
    "    \n",
    "    if confidence >= 80:\n",
    "        confidence_text = \"High confidence\"\n",
    "    elif confidence >= 60:\n",
    "        confidence_text = \"Moderate confidence\"\n",
    "    else:\n",
    "        confidence_text = \"Low confidence\"\n",
    "    \n",
    "    risk_level = \"High\" if risks >= 3 else \"Medium\" if risks >= 2 else \"Low\"\n",
    "    \n",
    "    return f\"{confidence_text} ({confidence}%), {risk_level} risk ({risks} factors)\"\n",
    "\n",
    "print(f\"\\nMonitoring Decision Summary: {summarize_prediction(impact_prediction)}\")\n",
    "print(f\"Microservices Decision Summary: {summarize_prediction(micro_prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19aaba10-be57-4ea5-ae6e-47207323dc27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Generate Decision Record\n",
    "**What this cell does:**\n",
    "\n",
    "- Function to create a formal ADR (Architectural Decision Record)\n",
    "- LLM helps write: context, options considered, consequences\n",
    "- Uses history to enrich the ADR with learned insights\n",
    "- Output: markdown-formatted ADR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0556cb09-79bd-4a3b-a3bf-9a42010c23f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_adr(decision: Dict[str, Any], history: List[Dict[str, Any]], predictions: Dict[str, Any] = None) -> str:\n",
    "    \"\"\"Generate a formal Architectural Decision Record using decision history and predictions.\"\"\"\n",
    "    # Get historical context\n",
    "    context = build_context_for_decision(\n",
    "        f\"{decision['decision_type']} {decision['title']}\", \n",
    "        history, \n",
    "        max_items=10\n",
    "    )\n",
    "    \n",
    "    # Get consistency analysis\n",
    "    consistency = analyze_decision_consistency(decision, history)\n",
    "    \n",
    "    prompt = f\"\"\"Generate a formal Architectural Decision Record (ADR) for this technical decision.\n",
    "\n",
    "DECISION DETAILS:\n",
    "{json.dumps(decision, indent=2)}\n",
    "\n",
    "HISTORICAL CONTEXT:\n",
    "{context}\n",
    "\n",
    "CONSISTENCY ANALYSIS:\n",
    "{json.dumps(consistency.get('analysis', {}), indent=2) if consistency.get('analysis') else 'Not available'}\n",
    "\n",
    "IMPACT PREDICTIONS:\n",
    "{json.dumps(predictions.get('predictions', {}), indent=2) if predictions else 'Not available'}\n",
    "\n",
    "Please create a comprehensive ADR following this structure:\n",
    "\n",
    "# ADR-[NUMBER]: [TITLE]\n",
    "\n",
    "## Status\n",
    "[Proposed/Accepted/Deprecated/Superseded]\n",
    "\n",
    "## Context\n",
    "[Detailed explanation of the problem and why a decision is needed]\n",
    "\n",
    "## Decision\n",
    "[The change that we're proposing or have agreed to implement]\n",
    "\n",
    "## Consequences\n",
    "[What becomes easier or more difficult as a result of this decision]\n",
    "\n",
    "### Positive Consequences\n",
    "[List positive outcomes]\n",
    "\n",
    "### Negative Consequences\n",
    "[List negative outcomes or trade-offs]\n",
    "\n",
    "## Options Considered\n",
    "[Detailed analysis of each alternative with pros/cons]\n",
    "\n",
    "## Related Decisions\n",
    "[Links to related ADRs based on historical context]\n",
    "\n",
    "## Lessons from History\n",
    "[Key insights from similar past decisions]\n",
    "\n",
    "## Implementation Notes\n",
    "[Specific guidance for implementing this decision]\n",
    "\n",
    "## Review Triggers\n",
    "[Conditions that would prompt revisiting this decision]\n",
    "\n",
    "Format as proper Markdown. Be specific and detailed based on the provided context.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",\n",
    "            max_tokens=2000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        return response.content[0].text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error generating ADR: {str(e)}\"\n",
    "\n",
    "# Generate ADR for the monitoring decision\n",
    "print(\"=== Generating ADR for DataDog Monitoring Decision ===\\n\")\n",
    "adr_content = generate_adr(monitoring_decision, Y, impact_prediction)\n",
    "print(adr_content)\n",
    "\n",
    "# Save ADR to a variable for potential file export\n",
    "monitoring_adr = adr_content\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Generate ADR for a decision that's already in our history (to show how consequences get included)\n",
    "print(\"=== Generating ADR for Historical Redis Decision ===\\n\")\n",
    "redis_decision = Y[4]  # The Redis caching decision\n",
    "redis_adr = generate_adr(redis_decision, Y)\n",
    "print(redis_adr)\n",
    "\n",
    "# Create a function to generate a summary ADR index\n",
    "def generate_adr_index(history: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    \"\"\"Generate an index of all decisions that could have ADRs.\"\"\"\n",
    "    decisions = [e for e in history if e.get('event_type') == 'technical_decision']\n",
    "    consequences = {c['original_decision_id']: c for c in history if c.get('event_type') == 'decision_consequence'}\n",
    "    \n",
    "    adr_index = []\n",
    "    for i, decision in enumerate(decisions, 1):\n",
    "        adr_entry = {\n",
    "            'ADR_Number': f\"ADR-{i:03d}\",\n",
    "            'Title': decision['title'],\n",
    "            'Type': decision['decision_type'],\n",
    "            'Date': decision['timestamp'][:10],\n",
    "            'Status': 'Implemented' if decision['id'] in consequences else 'Proposed',\n",
    "            'Has_Consequences': 'Yes' if decision['id'] in consequences else 'No'\n",
    "        }\n",
    "        \n",
    "        if decision['id'] in consequences:\n",
    "            outcome = consequences[decision['id']]['outcome']\n",
    "            if 'success' in outcome.lower() or 'achieved' in outcome.lower():\n",
    "                adr_entry['Outcome'] = 'Positive'\n",
    "            elif 'exceeded budget' in outcome.lower() or 'required' in outcome.lower():\n",
    "                adr_entry['Outcome'] = 'Mixed'\n",
    "            else:\n",
    "                adr_entry['Outcome'] = 'Negative'\n",
    "        else:\n",
    "            adr_entry['Outcome'] = 'TBD'\n",
    "        \n",
    "        adr_index.append(adr_entry)\n",
    "    \n",
    "    return pd.DataFrame(adr_index)\n",
    "\n",
    "print(\"=== ADR Index ===\")\n",
    "adr_index_df = generate_adr_index(Y)\n",
    "display(adr_index_df)\n",
    "\n",
    "# Create a template function for quick ADR generation\n",
    "def create_adr_template(decision_type: str) -> str:\n",
    "    \"\"\"Create a basic ADR template for a specific decision type.\"\"\"\n",
    "    templates = {\n",
    "        'database': {\n",
    "            'considerations': ['Performance requirements', 'Scalability needs', 'Consistency model', 'Cost projections'],\n",
    "            'risks': ['Vendor lock-in', 'Migration complexity', 'Operational overhead']\n",
    "        },\n",
    "        'architecture': {\n",
    "            'considerations': ['System complexity', 'Team expertise', 'Maintenance burden', 'Evolution path'],\n",
    "            'risks': ['Over-engineering', 'Under-engineering', 'Technical debt']\n",
    "        },\n",
    "        'infrastructure': {\n",
    "            'considerations': ['Operational complexity', 'Cost model', 'Security requirements', 'Compliance needs'],\n",
    "            'risks': ['Cost overruns', 'Skill gaps', 'Vendor dependencies']\n",
    "        },\n",
    "        'api': {\n",
    "            'considerations': ['Client needs', 'Performance requirements', 'Version strategy', 'Security model'],\n",
    "            'risks': ['Breaking changes', 'Performance degradation', 'Security vulnerabilities']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    template_data = templates.get(decision_type, templates['architecture'])\n",
    "    \n",
    "    return f\"\"\"# ADR-XXX: [Decision Title]\n",
    "\n",
    "## Status\n",
    "Proposed\n",
    "\n",
    "## Context\n",
    "[Describe the issue motivating this decision]\n",
    "\n",
    "## Decision\n",
    "[Describe the proposed solution]\n",
    "\n",
    "## Consequences\n",
    "\n",
    "### Positive Consequences\n",
    "- [Benefit 1]\n",
    "- [Benefit 2]\n",
    "\n",
    "### Negative Consequences  \n",
    "- [Trade-off 1]\n",
    "- [Trade-off 2]\n",
    "\n",
    "## Options Considered\n",
    "\n",
    "### Option 1: [Name]\n",
    "**Pros:**\n",
    "- [Pro 1]\n",
    "\n",
    "**Cons:**\n",
    "- [Con 1]\n",
    "\n",
    "## Key Considerations\n",
    "{chr(10).join(f'- {c}' for c in template_data['considerations'])}\n",
    "\n",
    "## Risk Factors\n",
    "{chr(10).join(f'- {r}' for r in template_data['risks'])}\n",
    "\n",
    "## Implementation Notes\n",
    "[Specific guidance]\n",
    "\n",
    "## Review Triggers\n",
    "- [Condition 1]\n",
    "- [Condition 2]\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Quick ADR Template for Infrastructure Decisions ===\")\n",
    "print(create_adr_template('infrastructure'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7ff32bc-9c02-42e0-9fbe-eb44f18ec693",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Decision Timeline Visualization\n",
    "**What this cell does:**\n",
    "\n",
    "- Create a simple timeline showing decisions chronologically\n",
    "- Color code by decision type\n",
    "- Shows the pattern of decision-making over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "449321c2-cb55-460c-86dc-84cacb6f50c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "# Prepare timeline data\n",
    "timeline_data = []\n",
    "for event in Y:\n",
    "    if event.get('event_type') == 'technical_decision':\n",
    "        timeline_data.append({\n",
    "            'timestamp': pd.to_datetime(event['timestamp']),\n",
    "            'title': event['title'],\n",
    "            'type': event['decision_type']\n",
    "        })\n",
    "\n",
    "df_timeline = pd.DataFrame(timeline_data)\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Color mapping for decision types\n",
    "colors = {\n",
    "    'database': '#E74C3C',      # Red\n",
    "    'architecture': '#3498DB',   # Blue\n",
    "    'infrastructure': '#2ECC71', # Green\n",
    "    'api': '#F39C12'            # Orange\n",
    "}\n",
    "\n",
    "# Plot each decision as a point on the timeline\n",
    "for decision_type in df_timeline['type'].unique():\n",
    "    type_data = df_timeline[df_timeline['type'] == decision_type]\n",
    "    plt.scatter(type_data['timestamp'], \n",
    "               [decision_type] * len(type_data),\n",
    "               c=colors.get(decision_type, '#999999'),\n",
    "               s=200,\n",
    "               alpha=0.8,\n",
    "               label=decision_type)\n",
    "\n",
    "# Add decision titles as annotations\n",
    "for _, row in df_timeline.iterrows():\n",
    "    plt.annotate(row['title'][:25] + '...' if len(row['title']) > 25 else row['title'],\n",
    "                xy=(row['timestamp'], row['type']),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points',\n",
    "                fontsize=8,\n",
    "                alpha=0.7)\n",
    "\n",
    "# Format the plot\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Decision Type', fontsize=12)\n",
    "plt.title('Technical Decision Timeline', fontsize=16, pad=20)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Format dates on x-axis\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=5))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== Timeline Summary ===\")\n",
    "print(f\"Total decisions tracked: {len(df_timeline)}\")\n",
    "print(f\"\\nDecisions by type:\")\n",
    "for decision_type, count in df_timeline['type'].value_counts().items():\n",
    "    print(f\"  {decision_type}: {count}\")\n",
    "\n",
    "time_span = df_timeline['timestamp'].max() - df_timeline['timestamp'].min()\n",
    "print(f\"\\nTime span: {time_span.total_seconds() / 60:.1f} minutes\")\n",
    "print(f\"Decision frequency: {len(df_timeline) / (time_span.total_seconds() / 3600):.1f} per hour\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "llm_assisted_decision_records",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
